{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability of least squares algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a least squares problem.  We'll fit a polynomial of degree 14 to the function \n",
    "\n",
    "$$e^{\\sin(4t)}.$$\n",
    "\n",
    "We'll normalize the function (based on knowledge of the exact answer) so that the correct answer for the leading coefficient of the interpolating polynomial is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100  # Sample at this many points\n",
    "n = 15   # Fit a polynomial of degree n-1\n",
    "\n",
    "t = np.linspace(0,1,m)\n",
    "A = np.zeros((m,n))\n",
    "for i in range(n):\n",
    "    A[:,i] = t**i      # Vandermonde matrix\n",
    "    \n",
    "b = np.exp(np.sin(4*t))  # Sampled function\n",
    "b = b/2006.787453080206  # Normalization\n",
    "plt.plot(b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's determine the least squares condition number for this problem.  Note that in order to do so, we have to actually solve the problem.  We also plot the fit, which is very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, res, rank, s = np.linalg.lstsq(A,b,rcond=-1)\n",
    "y = np.dot(A,x)\n",
    "kappa = np.linalg.cond(A)\n",
    "tantheta = norm(b-y)/norm(y)\n",
    "eta = norm(A)*norm(x)/norm(y)\n",
    "term2 = kappa**2 * tantheta/eta\n",
    "print('kappa: %0.2e' % kappa)\n",
    "print('theta: %0.2e' % np.arctan(tantheta))\n",
    "print('eta: %10.2e' % eta)\n",
    "print('kappa^2 * tan(theta)/eta: %10.2e' % term2)\n",
    "\n",
    "plt.plot(t,b,'-',t,y,'o'); plt.xlabel('x'); plt.ylabel('$f(x)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the matrix is very ill-conditioned (because of the high polynomial degree), but $\\theta$ is very small which means we can fit the data very well.  Recall our formula for the condition number:\n",
    "\n",
    "$$ \\kappa(A) + \\frac{\\kappa(A)^2 \\tan(\\theta)}{\\eta}. $$\n",
    "\n",
    "In this case, because $\\theta$ is small and $\\eta$ is fairly large, both terms are comparable.  Thus we get a condition number of about $\\kappa$, rather than $\\kappa^2$.  This is often the case when the problem is ill-conditioned and the fit is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('least squares condition number: %0.2e' % (kappa + kappa**2*tantheta/eta))\n",
    "print('kappa^2: %0.2e' % kappa**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we should hope to get perhaps 6 digits of accuracy from a backward-stable algorithm (in double precision).  Meanwhile, the error from using the normal equations will be governed by $\\kappa^2$, which is much larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution methods and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy QR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try numpy's built-in QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = np.linalg.qr(A)\n",
    "x = np.linalg.solve(R,np.dot(Q.T,b))\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does a bit better than what the analysis guarantees.  It seems this uses a backward-stable algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Householder QR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try using our own implementation of Householder factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def householder(A):\n",
    "    \"\"\"QR factorization via Householder triangularization.\"\"\"\n",
    "    m, n = A.shape\n",
    "    V = np.zeros(A.shape)\n",
    "    R = A.copy()\n",
    "    for k in range(n-1):\n",
    "        x = R[k:,k].copy()\n",
    "        x[0] = x[0] + np.sign(x[0])*np.linalg.norm(x,2)\n",
    "        x = x/np.linalg.norm(x,2)\n",
    "        V[k:,k] = x.copy()\n",
    "        for j in range(k,n):\n",
    "            R[k:,j] = R[k:,j] - 2*V[k:,k]*np.dot(V[k:,k].T,R[k:,j])\n",
    "    return V,R[:n,:]\n",
    "\n",
    "def apply_Q(V,x):\n",
    "    \"\"\"Algorithm 10.3 of Trefethen & Bau.\"\"\"\n",
    "    m, n = V.shape\n",
    "    for k in range(n-1,-1,-1):\n",
    "        x[k:] = x[k:] - 2*np.dot(V[k:,k],x[k:])*V[k:,k]\n",
    "    return x\n",
    "\n",
    "def compute_Q(V):\n",
    "    m, n = V.shape\n",
    "    Q = np.zeros((m,n))\n",
    "    for k in range(n):\n",
    "        x = np.zeros(m)\n",
    "        x[k] = 1.\n",
    "        Q[:,k] = apply_Q(V,x)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, R = householder(A)\n",
    "Q = compute_Q(V)\n",
    "x = np.linalg.solve(R,np.dot(Q.T,b))\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This answer is totally wrong!  What happened?  Let's check that $Q$ is unitary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(np.dot(Q.T,Q)-np.eye(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is, so what's wrong?  Even though Householder is backward stable, my method for applying $Q^T$ is not.  However, there is a sneaky way to avoid this problem.  We just append $b$ to $A$ as a final column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.append(A,b.reshape((m,1)),axis=1)\n",
    "V, R = householder(M)\n",
    "R2 = R[:n,:n]\n",
    "Qb = R[:n,n]\n",
    "x = np.linalg.solve(R2,Qb)\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the expected accuracy -- roughly the same as numpy's QR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Gram-Schmidt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try Modified Gram-Schmidt.  We already know this is an unstable algorithm for computing $Q$, but here goes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgs(A):\n",
    "    \"QR factorization by the modified Gram-Schmidt algorithm.\"\n",
    "    n = A.shape[1]\n",
    "    R = np.zeros([n,n])\n",
    "    V = np.zeros(A.shape)\n",
    "    Q = np.zeros(A.shape)\n",
    "    for i in range(n):\n",
    "        V[:,i] = A[:,i]\n",
    "    for i in range(n):\n",
    "        R[i,i] = np.linalg.norm(V[:,i],2)\n",
    "        Q[:,i] = V[:,i]/R[i,i]\n",
    "        for j in range(i,n):\n",
    "            R[i,j] = np.dot(Q[:,i].T,V[:,j])\n",
    "            V[:,j] = V[:,j] - R[i,j]*Q[:,i]\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = mgs(A)\n",
    "x = np.linalg.solve(R,np.dot(Q.T,b))\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(np.dot(Q.T,Q)-np.eye(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $Q$ matrix we get from MGS is not orthogonal, then $Q^T$ is not its inverse, and the algorithm fails.  There is again a sneaky way to get around this and avoid the need to use $Q^T$ explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.append(A,b.reshape((m,1)),axis=1)\n",
    "Q2, R = mgs(M)\n",
    "R2 = R[:n,:n]\n",
    "Qb = R[:n,n]\n",
    "x = np.linalg.solve(R2,Qb)\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented this way, MGS is just as good as the other algorithms we've tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the normal equations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(np.dot(A.T,A),np.dot(A.T,b))\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\kappa^2 \\approx 10^{20}$, we don't get a single accurate digit from this algorithm.\n",
    "However, the fact that $x$ is totally wrong doesn't necessarily mean $y$ is wrong.  Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.dot(A,x)\n",
    "plt.plot(t,b,'-',t,y,'o',lw=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: **The fact that your model fits the data very well says absolutely nothing about whether the model is correct!**  \n",
    "\n",
    "Also, if your least squares problem is ill-conditioned, then there can be vastly different models that fit the data almost equally well.  In this case it is a mistake to attach any meaning to the values of the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try the SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vstar = np.linalg.svd(A)\n",
    "x = np.dot(Vstar.T,np.dot(U[:,:n].T,b)/S)\n",
    "print(x[14]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is almost exactly the same accuracy as we got from numpy's built-in QR function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower-degree fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting a more-oscillatory function with just a quadratic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100  # Sample at this many points\n",
    "n = 3   # Fit a polynomial of degree n-1\n",
    "\n",
    "t = np.linspace(0,1,m)\n",
    "A = np.zeros((m,n))\n",
    "for i in range(n):\n",
    "    A[:,i] = t**i      # Vandermonde matrix\n",
    "    \n",
    "b = np.exp(np.sin(40*t))  # Sampled function\n",
    "\n",
    "x, res, rank, s = np.linalg.lstsq(A,b,rcond=-1)\n",
    "y = np.dot(A,x)\n",
    "kappa = np.linalg.cond(A)\n",
    "eta = norm(A)*norm(x)/norm(y)\n",
    "tantheta = norm(b-y)/norm(y)\n",
    "term2 = kappa**2*tantheta/eta\n",
    "\n",
    "print('kappa: %0.2e' % kappa)\n",
    "print('tan(theta): %0.2e' % tantheta)\n",
    "print('eta: %10.2e' % eta)\n",
    "print('kappa^2 * tan(theta)/eta: %10.2e' % term2)\n",
    "print('kappa^2: %0.2e' % kappa**2)\n",
    "plt.plot(t,b,'-',t,y,'o');\n",
    "\n",
    "# Use sympy to get \"exact\" solution\n",
    "import sympy\n",
    "def f(i,j):\n",
    "    return sympy.Rational(i,m-1)**j\n",
    "AA=sympy.Matrix(m,n,f)\n",
    "bb = sympy.Matrix(b)\n",
    "x_ex=AA.LDLsolve(bb)\n",
    "\n",
    "# Note that we don't bother to normalize this time because x_ex[-1] is approximately 1 anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the fit is not as good.  The value of $\\theta$ is correspondingly much larger.  Of course, the smaller vandermonde matrix $A$ is much better conditioned than before.\n",
    "\n",
    "Notice that now we expect the normal equations to be worse than a backward-stable algorithm by at most about a factor of 3.  Let's check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vstar = np.linalg.svd(A)\n",
    "xx = np.dot(Vstar.T,np.dot(U[:,:n].T,b)/S)\n",
    "print(xx[-1]-x_ex[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linalg.solve(np.dot(A.T,A),np.dot(A.T,b))\n",
    "print(xx[-1]-x_ex[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, for this case the normal equations give a result just as good as the SVD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
